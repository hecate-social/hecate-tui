# Hecate's Queue

*Commands from the goddess. Read and obey.*

---

## ğŸ“ CHANNEL TAGGING (NEW RULE â€” READ THIS)

**Effective immediately:** All RESPONSES.md entries MUST include channel tags.

This is the **[tui]** channel. When writing to RESPONSES.md:
- Prefix your title: `## 2026-02-03 COMPLETE [tui]: Task Name`
- Cross-references: `Related: Depends on [daemon] endpoint`

**All channels:**
- `[tui]` â€” hecate-tui (this repo)
- `[daemon]` â€” hecate-daemon
- `[node]` â€” hecate-node
- `[realm]` â€” hecate-realm
- `[macula-realm]` â€” macula-io/macula-realm

**Why:** I monitor multiple repos. Without tags, context is lost. Be explicit.

---

## âš ï¸ MANDATORY: Re-read CLAUDE.md NOW

**Before doing anything else this session:**

```bash
cat ~/work/github.com/CLAUDE.md
```

New rules have been added. Pay special attention to:
- **"NEVER DELETE FEATURES"** section
- Read the whole file before editing
- Extend, don't replace

**Acknowledge in RESPONSES.md that you've read it.**

---

## Protocol

| File | Your Access |
|------|-------------|
| `QUEUE.md` | **READ-ONLY** |
| `RESPONSES.md` | Write here |
| `STATUS.md` | Update here |

---

## ğŸ”´ HIGH: Chat View + LLM Client

**TOP PRIORITY. The TUI becomes a window into intelligence.**

Read `plans/PLAN_CHAT_VIEW.md` for the full design.

**Phase 1: Local Chat Only**

Create these files:

```
internal/
â”œâ”€â”€ client/
â”‚   â””â”€â”€ llm.go             # LLM methods on existing client
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ types.go           # Message, Model, ChatRequest, etc.
â”‚   â””â”€â”€ stream.go          # SSE stream parser
â””â”€â”€ views/
    â””â”€â”€ chat/
        â”œâ”€â”€ chat.go        # Main Bubble Tea model
        â”œâ”€â”€ messages.go    # Message list component
        â”œâ”€â”€ input.go       # Input textarea
        â””â”€â”€ styles.go      # Lip Gloss styles
```

**Implement:**
1. `internal/llm/types.go` â€” Message, Model, ChatRequest, ChatResponse
2. `internal/llm/stream.go` â€” SSE parser for streaming responses
3. `internal/client/llm.go` â€” `ListModels()`, `ChatStream()`
4. `internal/views/chat/` â€” Bubble Tea chat view
   - Model selector (Tab to cycle)
   - Message history viewport
   - Input textarea
   - Streaming response display

**Key bindings:**
- `Enter` â€” send message
- `Tab` â€” cycle models  
- `Ctrl+C` / `Esc` â€” exit chat view
- `â†‘/â†“` â€” scroll history

**Depends on:** Daemon `GET /api/llm/models` and `POST /api/llm/chat` endpoints.

The daemon is building the backend: `hecate-daemon/.hecate/QUEUE.md`

**Test flow:**
```bash
# 1. Start Ollama
ollama run llama3.2

# 2. Start daemon
./hecate-daemon

# 3. Start TUI, navigate to Chat view
./hecate-tui
# Press 'c' for chat (or whatever key you assign)
```

**Phase 2 (later):** Mesh discovery, remote model routing.

---

## Active Tasks

### âœ… DONE [tui]: Fix Endpoint Mismatch

Fixed in this session. **COMMIT AND PUSH NOW.**

---

### ğŸ”´ HIGH [tui]: Chat View + LLM Client â€” UNBLOCKED

**The daemon LLM API is DONE.** You built it yourself:
- Phase 1: `d604efb` â€” serve_llm app
- Phase 2: `6e40a5b` â€” mesh announcement
- Phase 3: `3a8278f` â€” RPC listener

**Endpoints ready:**
```
GET  /api/llm/models   â†’ list Ollama models
POST /api/llm/chat     â†’ chat completion (SSE streaming)
GET  /api/llm/health   â†’ backend status
```

**Proceed with TUI chat view implementation.** See `plans/PLAN_CHAT_VIEW.md`.

---

### ğŸŸ¡ MEDIUM [tui]: Project Context Support (HECATE.md)

**Hecate TUI is THE AI interface. Not Claude. Not anything else.**

The TUI should read project context files, just like other AI coding tools.

**Context files to support:**

| File | Scope | Purpose |
|------|-------|---------|
| `HECATE.md` | Project root | Project-specific instructions |
| `SKILLS.md` | Project root | Specialized capabilities |
| `.hecate/config.yaml` | Workspace | TUI settings, preferences |
| `.hecate/memory/` | Workspace | Conversation history, context |

**Implementation:**

```
internal/
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ loader.go          # Find and load context files
â”‚   â”œâ”€â”€ hecate_md.go       # Parse HECATE.md
â”‚   â”œâ”€â”€ skills.go          # Parse SKILLS.md
â”‚   â””â”€â”€ memory.go          # Load/save conversation memory
```

**Behavior:**

1. On startup, walk up from cwd looking for `HECATE.md`
2. Load project context into system prompt
3. Load any `SKILLS.md` as additional capabilities
4. Include context when sending chat requests to LLM

**HECATE.md format (same as CLAUDE.md):**

```markdown
# Project Name

Brief description.

## Architecture

Key patterns, conventions.

## Commands

Common tasks, how to run them.

## Guidelines

Do's and don'ts for this project.
```

**This makes Hecate TUI a first-class AI coding assistant.**

---

### ğŸŸ¡ MEDIUM: Pairing UI Polish

Basic pairing works. Polish it:
- Better QR code display
- Progress indicator during polling
- Nicer success/error states
- Timeout handling

### ğŸŸ¡ MEDIUM: Identity View

After pairing works, flesh out Identity view:
- Agent MRI and profile
- Pairing status (which realm, when)
- Daemon status (running, version, uptime)
- Re-pair / unpair actions

### ğŸŸ¢ LOW: Coach Rules Engine

Read the Architecture Decisions in `plans/PLAN_HECATE_STUDIO_UX.md`.

**Coach is rules-based, NOT LLM-based:**
- Detect `services/`, `helpers/`, `utils/` â†’ regex on paths
- Catch central supervisors â†’ naming patterns
- Generate corrections â†’ templates

No LLM needed for doctrine enforcement.

---

## Architecture Decisions (READ THIS)

**1. Macula Services are NOT AI-powered**

Services on the mesh are pure business logic. Deterministic. Testable. No LLM runtime.

**2. Two distinct concerns in the TUI:**

| Concern | Implementation | LLM Required |
|---------|----------------|--------------|
| **Coach** (doctrine enforcement) | Rules engine, pattern matching | No |
| **Studio** (code generation) | LLM generates Cartwheel code | **Yes** |

**3. First-run experience:**
- If no model configured, prompt user to set up
- Detect local Ollama, offer easy path
- Or enter cloud API key

---

## Completed Tasks

### âœ… Basic TUI Structure
- Views: Status, Mesh, Capabilities, RPC, Logs
- Tab navigation
- Daemon client connection

### âœ… Basic Pairing Flow
- QR code display
- Polling logic
- Success/error handling

---

*Ship it.* ğŸ”¥ğŸ—ï¸ğŸ”¥
